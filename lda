#安装包
pip install pandas
pip install --user gensim



#引入包
import os
import pandas as pd
import jieba
from gensim import corpora,models


#准备工作
os.getcwd()

#数据预览
pd.read_table('./lda/data/100reviews.txt')
data.loc[0]
type(data)
data.shape

data.index
data.columns
data.values

#配置文件路径，数据读入
inputfile = './lda/data/100reviews.txt'
outputfile = './lda/data/100reviews_process_1.txt'
data = pd.read_table(inputfile,encoding ='utf-8',header=0)

#删除重复评论
data=pd.DataFrame(data['content_body'].unique())
data.to_csv(outputfile,index= False, header= False, encoding = 'utf-8')

#分词
outputfile1 = './lda/data/100reviews_process_cut.txt'
mycut=lambda s: ' '.join(jieba.cut(s))
data1 = data[0].apply(mycut)
data1.to_csv(outputfile2,index= False, header= False, encoding = 'utf-8')


#LDA 
file = './lda/data/100reviews_process_cut.txt'
data = pd.read_csv(file, encoding = 'utf-8', header = None)
stoplist = './lda/data/cn_stopWords.txt'
stop = pd.read_csv(stoplist, encoding = 'utf-8', header = None)
stop = [' ',''] + list(stop[0])

data[1] = data[0].apply(lambda s: s.split(' '))
data[2] = data[1].apply(lambda x:[i for i in x if i not in stop])

#建立词典
dict = corpora.Dictionary(data[2])
#建立语料库: 转换语料为 Document - Term 矩阵
corpus = [dict.doc2bow(i) for i in data[2]]
#LDA模型
lda = models.LdaModel(corpus, num_topics = 2, id2word = dict)
#查看最终的主题分类结果
topic=[]
for i in range(2):
    print(i)
    a=lda.get_document_topics(corpus)[i]
    print(a)
    topic.append(a)
#查看具体的top词语与主题
for i in range(2):
    print(lda.print_topic(i))
    
